{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19448637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 06:55:09.923117: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 06:55:10.121993: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-10 06:55:10.954578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64\n",
      "2023-11-10 06:55:10.954671: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.6/lib64\n",
      "2023-11-10 06:55:10.954679: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0]\n",
      " [ 0  0]\n",
      " [ 0  0]\n",
      " ...\n",
      " [11 59]\n",
      " [11 59]\n",
      " [11 59]]\n",
      "(18000, 150, 150)\n",
      "[ 0  0  0 ... 23 23 23]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "\n",
    "images = np.load('/home/s3963616/IDL/images_L.npy')\n",
    "labels = np.load('/home/s3963616/IDL/labels.npy')\n",
    "print(labels)\n",
    "print(images.shape)\n",
    "\n",
    "categories = np.zeros_like(labels[:, 0])\n",
    "\n",
    "for i in range(12):\n",
    "   \n",
    "    categories[(labels[:, 0] == i) & (labels[:, 1] < 30)] = 2 * i\n",
    "    categories[(labels[:, 0] == i) & (labels[:, 1] >= 30)] = 2 * i + 1\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ece64a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 148, 148, 16)     64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 72, 72, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 34, 34, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 32)        18464     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 15, 15, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               401664    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                6168      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 450,168\n",
      "Trainable params: 449,880\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 05:08:19.796720: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 05:08:23.755159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9375 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n",
      "2023-11-10 05:08:23.755794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 782 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 05:08:27.591230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8800\n",
      "2023-11-10 05:08:29.067280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-10 05:08:29.074643: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f41e7676aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-10 05:08:29.074671: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-11-10 05:08:29.074677: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-11-10 05:08:29.081045: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-10 05:08:29.317223: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 10s 36ms/step - loss: 3.2812 - accuracy: 0.0467 - val_loss: 5.7247 - val_accuracy: 0.0413\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 3.1556 - accuracy: 0.0498 - val_loss: 6.3799 - val_accuracy: 0.0413\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 2s 26ms/step - loss: 3.0517 - accuracy: 0.0698 - val_loss: 4.0791 - val_accuracy: 0.0413\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 2.8758 - accuracy: 0.0946 - val_loss: 3.1061 - val_accuracy: 0.0750\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 2.6859 - accuracy: 0.1374 - val_loss: 3.0587 - val_accuracy: 0.0917\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 2.4733 - accuracy: 0.1703 - val_loss: 2.4976 - val_accuracy: 0.1872\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 2.2881 - accuracy: 0.2134 - val_loss: 2.6008 - val_accuracy: 0.1837\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 2.1162 - accuracy: 0.2557 - val_loss: 2.8545 - val_accuracy: 0.1205\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 1.9488 - accuracy: 0.3097 - val_loss: 2.9923 - val_accuracy: 0.1139\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 1.7664 - accuracy: 0.3494 - val_loss: 2.1272 - val_accuracy: 0.2931\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 1.6016 - accuracy: 0.4081 - val_loss: 1.9641 - val_accuracy: 0.4010\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 1.4434 - accuracy: 0.4641 - val_loss: 3.5058 - val_accuracy: 0.2302\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 1.2835 - accuracy: 0.5198 - val_loss: 5.2407 - val_accuracy: 0.0747\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 1.1525 - accuracy: 0.5671 - val_loss: 1.8995 - val_accuracy: 0.3594\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 1.0385 - accuracy: 0.6121 - val_loss: 1.3289 - val_accuracy: 0.5663\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.9419 - accuracy: 0.6431 - val_loss: 0.9110 - val_accuracy: 0.6771\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.8507 - accuracy: 0.6767 - val_loss: 2.7892 - val_accuracy: 0.3104\n",
      "Epoch 18/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.7972 - accuracy: 0.7009 - val_loss: 4.9465 - val_accuracy: 0.1149\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.7257 - accuracy: 0.7274 - val_loss: 3.5417 - val_accuracy: 0.2083\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.6672 - accuracy: 0.7418 - val_loss: 1.8944 - val_accuracy: 0.5146\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.6127 - accuracy: 0.7673 - val_loss: 1.8360 - val_accuracy: 0.4826\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.5735 - accuracy: 0.7905 - val_loss: 0.5865 - val_accuracy: 0.8014\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5308 - accuracy: 0.8003 - val_loss: 1.3890 - val_accuracy: 0.5552\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.5017 - accuracy: 0.8109 - val_loss: 0.7321 - val_accuracy: 0.7500\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4934 - accuracy: 0.8142 - val_loss: 4.2381 - val_accuracy: 0.2333\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4356 - accuracy: 0.8375 - val_loss: 0.4202 - val_accuracy: 0.8687\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4230 - accuracy: 0.8423 - val_loss: 0.3957 - val_accuracy: 0.8615\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.4142 - accuracy: 0.8439 - val_loss: 3.6168 - val_accuracy: 0.2681\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.3863 - accuracy: 0.8543 - val_loss: 1.3049 - val_accuracy: 0.6392\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3563 - accuracy: 0.8685 - val_loss: 0.3119 - val_accuracy: 0.9007\n",
      "113/113 [==============================] - 1s 4ms/step\n",
      "Test Loss: 0.3546\n",
      "Test Accuracy: 0.8867\n",
      "Common Sense Accuracy (Mean Time Difference): 3.1 minutes\n"
     ]
    }
   ],
   "source": [
    "# start to train\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "images_expanded = np.expand_dims(images, -1)\n",
    "images_expanded = images_expanded.astype('float32') / 255.0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_expanded, categories, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = len(np.unique(categories))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),  \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu'),  \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),  \n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=30, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "def calculate_time_difference(true_category, pred_category):\n",
    "    \n",
    "    true_minutes = (true_category // 6) * 60 + (true_category % 6) * 10\n",
    "    pred_minutes = (pred_category // 6) * 60 + (pred_category % 6) * 10\n",
    "    \n",
    "    diff = abs(true_minutes - pred_minutes)\n",
    "    \n",
    "    if diff > 360:  \n",
    "        diff = 720 - diff\n",
    "    return diff\n",
    "\n",
    "\n",
    "def common_sense_accuracy(y_true_classes, y_pred_classes):\n",
    "    total_samples = len(y_true_classes)\n",
    "    total_difference = 0\n",
    "    for i in range(total_samples):\n",
    "        total_difference += calculate_time_difference(y_true_classes[i], y_pred_classes[i])\n",
    "    \n",
    "    mean_difference = total_difference / total_samples\n",
    "    return mean_difference\n",
    "\n",
    "\n",
    "mean_diff = common_sense_accuracy(y_test_classes, y_pred_classes)\n",
    "print(f\"Common Sense Accuracy (Mean Time Difference): {mean_diff} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad398943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we transfer labels in 72 categories, every ten minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10a7e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 71 71 71] 18000\n"
     ]
    }
   ],
   "source": [
    "categories_10min = np.zeros_like(labels[:, 0])\n",
    "\n",
    "for hour in range(12):  \n",
    "    for ten_minute_mark in range(6): \n",
    "        start_min = ten_minute_mark * 10\n",
    "        end_min = (ten_minute_mark + 1) * 10\n",
    "        categories_10min[(labels[:, 0] == hour) & (labels[:, 1] >= start_min) & (labels[:, 1] < end_min)] = hour * 6 + ten_minute_mark\n",
    "\n",
    "print(categories_10min, len(categories_10min))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense 128 - 256 -512 -1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4550ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_55 (Conv2D)          (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " batch_normalization_55 (Bat  (None, 148, 148, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 74, 74, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_56 (Conv2D)          (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 72, 72, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 36, 36, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 34, 34, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 17, 17, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 15, 15, 48)        27696     \n",
      "                                                                 \n",
      " batch_normalization_58 (Bat  (None, 15, 15, 48)       192       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 7, 7, 48)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 2352)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1024)              2409472   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 72)                73800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,534,904\n",
      "Trainable params: 2,534,584\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "90/90 [==============================] - 6s 34ms/step - loss: 4.4665 - accuracy: 0.0153 - val_loss: 9.3777 - val_accuracy: 0.0135\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 4.2340 - accuracy: 0.0200 - val_loss: 11.2634 - val_accuracy: 0.0135\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 4.1029 - accuracy: 0.0275 - val_loss: 10.1259 - val_accuracy: 0.0135\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 3.8710 - accuracy: 0.0494 - val_loss: 6.0229 - val_accuracy: 0.0135\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 3.5013 - accuracy: 0.0894 - val_loss: 7.6460 - val_accuracy: 0.0184\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 3.0929 - accuracy: 0.1268 - val_loss: 4.6659 - val_accuracy: 0.0556\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 2.6974 - accuracy: 0.1877 - val_loss: 8.5439 - val_accuracy: 0.0399\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 2.3828 - accuracy: 0.2451 - val_loss: 3.7236 - val_accuracy: 0.1052\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 2.1081 - accuracy: 0.3011 - val_loss: 4.1443 - val_accuracy: 0.1097\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 1.9065 - accuracy: 0.3500 - val_loss: 4.8372 - val_accuracy: 0.0997\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 1.7156 - accuracy: 0.4041 - val_loss: 3.2093 - val_accuracy: 0.2059\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 1.5455 - accuracy: 0.4634 - val_loss: 1.5656 - val_accuracy: 0.4899\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 1.3761 - accuracy: 0.5184 - val_loss: 16.0896 - val_accuracy: 0.0573\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 1.2536 - accuracy: 0.5554 - val_loss: 3.8349 - val_accuracy: 0.2076\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 1.1163 - accuracy: 0.6065 - val_loss: 0.9099 - val_accuracy: 0.6816\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.9974 - accuracy: 0.6479 - val_loss: 1.9845 - val_accuracy: 0.4517\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.9037 - accuracy: 0.6814 - val_loss: 3.3603 - val_accuracy: 0.3375\n",
      "Epoch 18/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.8234 - accuracy: 0.7074 - val_loss: 3.2781 - val_accuracy: 0.2788\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.7651 - accuracy: 0.7313 - val_loss: 0.8264 - val_accuracy: 0.7226\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.6947 - accuracy: 0.7547 - val_loss: 1.8224 - val_accuracy: 0.4667\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.6450 - accuracy: 0.7728 - val_loss: 1.4382 - val_accuracy: 0.6240\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.5848 - accuracy: 0.7934 - val_loss: 6.0497 - val_accuracy: 0.2844\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.5366 - accuracy: 0.8096 - val_loss: 4.5925 - val_accuracy: 0.3764\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.5046 - accuracy: 0.8187 - val_loss: 0.6192 - val_accuracy: 0.7969\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4707 - accuracy: 0.8333 - val_loss: 6.3813 - val_accuracy: 0.2062\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.4176 - accuracy: 0.8512 - val_loss: 0.8114 - val_accuracy: 0.7361\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.3907 - accuracy: 0.8601 - val_loss: 2.6844 - val_accuracy: 0.5281\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.3758 - accuracy: 0.8664 - val_loss: 0.5929 - val_accuracy: 0.8059\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3452 - accuracy: 0.8780 - val_loss: 5.8690 - val_accuracy: 0.2771\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3272 - accuracy: 0.8823 - val_loss: 1.3236 - val_accuracy: 0.6323\n",
      "113/113 [==============================] - 1s 4ms/step\n",
      "Test Loss: 1.2833\n",
      "Test Accuracy: 0.6369\n",
      "Common Sense Accuracy (Mean Time Difference): 26.144444444444446 minutes\n"
     ]
    }
   ],
   "source": [
    "# start to train\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "images_expanded = np.expand_dims(images, -1)\n",
    "images_expanded = images_expanded.astype('float32') / 255.0\n",
    "# switch labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_expanded, categories_10min, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "num_classes = len(np.unique(categories_10min))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),  \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(48, (3, 3), activation='relu'), \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),  \n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=30, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "def calculate_time_difference(true_category, pred_category):\n",
    "    true_minutes = (true_category // 6) * 60 + (true_category % 6) * 10\n",
    "    pred_minutes = (pred_category // 6) * 60 + (pred_category % 6) * 10\n",
    "    diff = abs(true_minutes - pred_minutes)\n",
    "    \n",
    "    if diff > 360:  \n",
    "        diff = 720 - diff\n",
    "    return diff\n",
    "\n",
    "\n",
    "def common_sense_accuracy(y_true_classes, y_pred_classes):\n",
    "    total_samples = len(y_true_classes)\n",
    "    total_difference = 0\n",
    "    for i in range(total_samples):\n",
    "        total_difference += calculate_time_difference(y_true_classes[i], y_pred_classes[i])\n",
    "    mean_difference = total_difference / total_samples\n",
    "    return mean_difference\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "mean_diff = common_sense_accuracy(y_test_classes, y_pred_classes)\n",
    "print(f\"Common Sense Accuracy (Mean Time Difference): {mean_diff} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we transfer labels into 720 categories, which are huge and the accuracy is relatively low without saying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b62a56fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ... 719 719 719] 18000\n"
     ]
    }
   ],
   "source": [
    "categories_1min = np.zeros_like(labels[:, 0])\n",
    "\n",
    "for hour in range(12):  \n",
    "    for minute in range(60):  \n",
    "        categories_1min[(labels[:, 0] == hour) & (labels[:, 1] == minute)] = hour * 60 + minute\n",
    "\n",
    "print(categories_1min, len(categories_1min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "905851d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_35 (Conv2D)          (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 148, 148, 16)     64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 74, 74, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 72, 72, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 36, 36, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 34, 34, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 17, 17, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 15, 15, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 15, 15, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 5, 5, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 5, 5, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 2, 2, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 720)               369360    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,288,464\n",
      "Trainable params: 1,287,472\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "90/90 [==============================] - 7s 36ms/step - loss: 6.6418 - accuracy: 0.0012 - val_loss: 12.4445 - val_accuracy: 0.0014\n",
      "Epoch 2/30\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 6.5763 - accuracy: 0.0014 - val_loss: 19.0085 - val_accuracy: 0.0014\n",
      "Epoch 3/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 6.5656 - accuracy: 0.0023 - val_loss: 14.6608 - val_accuracy: 0.0014\n",
      "Epoch 4/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 6.5365 - accuracy: 0.0031 - val_loss: 10.3073 - val_accuracy: 6.9444e-04\n",
      "Epoch 5/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 6.5005 - accuracy: 0.0024 - val_loss: 6.7194 - val_accuracy: 0.0010\n",
      "Epoch 6/30\n",
      "90/90 [==============================] - 3s 33ms/step - loss: 6.4361 - accuracy: 0.0045 - val_loss: 6.9690 - val_accuracy: 0.0010\n",
      "Epoch 7/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 6.3487 - accuracy: 0.0069 - val_loss: 7.0462 - val_accuracy: 0.0010\n",
      "Epoch 8/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 6.2195 - accuracy: 0.0090 - val_loss: 6.5336 - val_accuracy: 0.0035\n",
      "Epoch 9/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 6.0857 - accuracy: 0.0114 - val_loss: 6.6013 - val_accuracy: 0.0021\n",
      "Epoch 10/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 5.9135 - accuracy: 0.0162 - val_loss: 7.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 5.7112 - accuracy: 0.0214 - val_loss: 5.9496 - val_accuracy: 0.0128\n",
      "Epoch 12/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 5.5021 - accuracy: 0.0323 - val_loss: 6.3668 - val_accuracy: 0.0073\n",
      "Epoch 13/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 5.2389 - accuracy: 0.0376 - val_loss: 10.3822 - val_accuracy: 0.0042\n",
      "Epoch 14/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 4.9926 - accuracy: 0.0476 - val_loss: 10.9740 - val_accuracy: 0.0028\n",
      "Epoch 15/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 4.7636 - accuracy: 0.0569 - val_loss: 5.4457 - val_accuracy: 0.0184\n",
      "Epoch 16/30\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 4.5401 - accuracy: 0.0758 - val_loss: 7.5043 - val_accuracy: 0.0104\n",
      "Epoch 17/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 4.3283 - accuracy: 0.0898 - val_loss: 6.9596 - val_accuracy: 0.0118\n",
      "Epoch 18/30\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 4.1496 - accuracy: 0.0996 - val_loss: 4.4520 - val_accuracy: 0.0698\n",
      "Epoch 19/30\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 3.9773 - accuracy: 0.1182 - val_loss: 6.8758 - val_accuracy: 0.0194\n",
      "Epoch 20/30\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 3.8314 - accuracy: 0.1316 - val_loss: 8.1206 - val_accuracy: 0.0083\n",
      "Epoch 21/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 3.6792 - accuracy: 0.1462 - val_loss: 4.4231 - val_accuracy: 0.0604\n",
      "Epoch 22/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 3.5200 - accuracy: 0.1613 - val_loss: 8.9509 - val_accuracy: 0.0125\n",
      "Epoch 23/30\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 3.3646 - accuracy: 0.1797 - val_loss: 15.1119 - val_accuracy: 0.0049\n",
      "Epoch 24/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 3.2369 - accuracy: 0.1951 - val_loss: 4.0857 - val_accuracy: 0.0747\n",
      "Epoch 25/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 3.1237 - accuracy: 0.2128 - val_loss: 4.7893 - val_accuracy: 0.0663\n",
      "Epoch 26/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 3.0074 - accuracy: 0.2234 - val_loss: 4.3531 - val_accuracy: 0.0913\n",
      "Epoch 27/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 2.9051 - accuracy: 0.2427 - val_loss: 5.5203 - val_accuracy: 0.0417\n",
      "Epoch 28/30\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 2.8271 - accuracy: 0.2576 - val_loss: 5.0002 - val_accuracy: 0.0545\n",
      "Epoch 29/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 2.7330 - accuracy: 0.2689 - val_loss: 4.4592 - val_accuracy: 0.0861\n",
      "Epoch 30/30\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 2.6574 - accuracy: 0.2799 - val_loss: 7.8547 - val_accuracy: 0.0271\n",
      "113/113 [==============================] - 1s 5ms/step\n",
      "Test Loss: 7.9916\n",
      "Test Accuracy: 0.0278\n",
      "Common Sense Accuracy (Mean Time Difference): -866.6694444444445 minutes\n"
     ]
    }
   ],
   "source": [
    "# start to train\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "images_expanded = np.expand_dims(images, -1)\n",
    "images_expanded = images_expanded.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images_expanded, categories_1min, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "num_classes = len(np.unique(categories_1min))\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'), \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'), \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu'),  \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=30, validation_split=0.2)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "def calculate_time_difference(true_category, pred_category):\n",
    "    \n",
    "    true_minutes = (true_category // 6) * 60 + (true_category % 6) * 10\n",
    "    pred_minutes = (pred_category // 6) * 60 + (pred_category % 6) * 10\n",
    "   \n",
    "    diff = abs(true_minutes - pred_minutes)\n",
    "   \n",
    "    if diff > 360:  \n",
    "        diff = 720 - diff\n",
    "    return diff\n",
    "\n",
    "\n",
    "def common_sense_accuracy(y_true_classes, y_pred_classes):\n",
    "    total_samples = len(y_true_classes)\n",
    "    total_difference = 0\n",
    "    for i in range(total_samples):\n",
    "        total_difference += calculate_time_difference(y_true_classes[i], y_pred_classes[i])\n",
    "\n",
    "    mean_difference = total_difference / total_samples\n",
    "    return mean_difference\n",
    "\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "mean_diff = common_sense_accuracy(y_test_classes, y_pred_classes)\n",
    "print(f\"Common Sense Accuracy (Mean Time Difference): {mean_diff} minutes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5caad0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18000, 2)\n",
      "(18000, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "images = np.load('/home/s3963616/IDL/images_L.npy')\n",
    "labels = np.load('/home/s3963616/IDL/labels.npy')\n",
    "print(labels.shape)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5cd013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "hours = labels[:, 0]\n",
    "minutes = labels[:, 1] / 60 \n",
    "continuous_labels = hours + minutes  \n",
    "for i in range(10):\n",
    "    print(continuous_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f460899a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_173 (Conv2D)         (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " batch_normalization_173 (Ba  (None, 148, 148, 16)     64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_173 (MaxPooli  (None, 74, 74, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_174 (Conv2D)         (None, 72, 72, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_174 (Ba  (None, 72, 72, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_174 (MaxPooli  (None, 36, 36, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_175 (Conv2D)         (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_175 (Ba  (None, 34, 34, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_175 (MaxPooli  (None, 17, 17, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 15, 15, 512)       295424    \n",
      "                                                                 \n",
      " batch_normalization_176 (Ba  (None, 15, 15, 512)      2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_176 (MaxPooli  (None, 7, 7, 512)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_177 (Conv2D)         (None, 5, 5, 96)          442464    \n",
      "                                                                 \n",
      " batch_normalization_177 (Ba  (None, 5, 5, 96)         384       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_177 (MaxPooli  (None, 2, 2, 96)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 384)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1824)              702240    \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 1824)              0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 1825      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,468,129\n",
      "Trainable params: 1,466,689\n",
      "Non-trainable params: 1,440\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 7s 21ms/step - loss: 9.3772 - val_loss: 65.3368\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 5.7219 - val_loss: 18.8986\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 3.6420 - val_loss: 16.4270\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 2.3336 - val_loss: 10.5406\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 1.5969 - val_loss: 12.9340\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 1.1064 - val_loss: 11.5742\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.7243 - val_loss: 4.6332\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6209 - val_loss: 7.3841\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4721 - val_loss: 3.1937\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4061 - val_loss: 4.7720\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5786 - val_loss: 8.1065\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5145 - val_loss: 2.8837\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4100 - val_loss: 1.0954\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3399 - val_loss: 2.7494\n",
      "Epoch 15/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3169 - val_loss: 4.8753\n",
      "Epoch 16/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2782 - val_loss: 3.1963\n",
      "Epoch 17/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5601 - val_loss: 7.0303\n",
      "Epoch 18/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6578 - val_loss: 4.6369\n",
      "Epoch 19/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3834 - val_loss: 15.0493\n",
      "Epoch 20/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3525 - val_loss: 10.4366\n",
      "Epoch 21/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2568 - val_loss: 0.6230\n",
      "Epoch 22/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2358 - val_loss: 10.4396\n",
      "Epoch 23/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2019 - val_loss: 8.4823\n",
      "Epoch 24/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2003 - val_loss: 5.9606\n",
      "Epoch 25/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1788 - val_loss: 1.0852\n",
      "Epoch 26/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3497 - val_loss: 9.7276\n",
      "Epoch 27/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3676 - val_loss: 14.6132\n",
      "Epoch 28/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.8938 - val_loss: 13.5274\n",
      "Epoch 29/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4461 - val_loss: 0.7631\n",
      "Epoch 30/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2372 - val_loss: 1.7490\n",
      "113/113 [==============================] - 1s 5ms/step\n",
      "Common Sense Error: 49.23 minutes\n",
      "Test Loss: 1.6238\n"
     ]
    }
   ],
   "source": [
    "# start to train\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, Dense\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "images_expanded = np.expand_dims(images, -1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train_continuous, y_test_continuous = train_test_split(images_expanded, continuous_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "he_normal = HeNormal()\n",
    "l1_l2_reg = l1_l2(l1=0.01, l2=0.001)\n",
    "l2_reg = l2(0.001)  \n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu'),  \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(96, (3, 3), activation='relu'),  \n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(1824, activation='relu'), \n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(1)  \n",
    "])\n",
    "\n",
    "adam_optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='mean_squared_error')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train_continuous, batch_size=64, epochs=30, validation_split=0.2)\n",
    "\n",
    "\n",
    "y_pred_continuous = model.predict(X_test).flatten()\n",
    "\n",
    "\n",
    "def calculate_common_sense_error(y_true, y_pred):\n",
    "    error = np.abs(y_true - y_pred)\n",
    "    error = np.minimum(error, 24 - error)  \n",
    "    error *= 60 \n",
    "    return np.mean(error)\n",
    "\n",
    "\n",
    "common_sense_error = calculate_common_sense_error(y_test_continuous, y_pred_continuous)\n",
    "print(f\"Common Sense Error: {common_sense_error:.2f} minutes\")\n",
    "\n",
    "\n",
    "test_loss = model.evaluate(X_test, y_test_continuous, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc316401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 150, 150, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 148, 148, 32  320         ['input_16[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 148, 148, 32  128        ['conv2d_75[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_75 (MaxPooling2D  (None, 74, 74, 32)  0           ['batch_normalization_75[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 72, 72, 64)   18496       ['max_pooling2d_75[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 72, 72, 64)  256         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_76 (MaxPooling2D  (None, 36, 36, 64)  0           ['batch_normalization_76[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 34, 34, 128)  73856       ['max_pooling2d_76[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 34, 34, 128)  512        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_77 (MaxPooling2D  (None, 17, 17, 128)  0          ['batch_normalization_77[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 15, 15, 256)  295168      ['max_pooling2d_77[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 15, 15, 256)  1024       ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_78 (MaxPooling2D  (None, 7, 7, 256)   0           ['batch_normalization_78[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 5, 5, 128)    295040      ['max_pooling2d_78[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 5, 5, 128)   512         ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_79 (MaxPooling2D  (None, 2, 2, 128)   0           ['batch_normalization_79[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 512)          0           ['max_pooling2d_79[0][0]']       \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1024)         525312      ['flatten_15[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 1024)         0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " hours_output (Dense)           (None, 1)            1025        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      " minutes_output (Dense)         (None, 1)            1025        ['dropout_15[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,212,674\n",
      "Trainable params: 1,211,458\n",
      "Non-trainable params: 1,216\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 9s 28ms/step - loss: 5.5818 - hours_output_loss: 10.7682 - minutes_output_loss: 0.3955 - val_loss: 102.9565 - val_hours_output_loss: 205.0105 - val_minutes_output_loss: 0.9026\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 3.5295 - hours_output_loss: 6.9202 - minutes_output_loss: 0.1389 - val_loss: 30.8713 - val_hours_output_loss: 57.6672 - val_minutes_output_loss: 4.0753\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 2.4509 - hours_output_loss: 4.8006 - minutes_output_loss: 0.1012 - val_loss: 35.1839 - val_hours_output_loss: 67.0039 - val_minutes_output_loss: 3.3638\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 1.7083 - hours_output_loss: 3.3330 - minutes_output_loss: 0.0837 - val_loss: 2.0402 - val_hours_output_loss: 3.9982 - val_minutes_output_loss: 0.0821\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 1.1906 - hours_output_loss: 2.3074 - minutes_output_loss: 0.0738 - val_loss: 3.2144 - val_hours_output_loss: 6.3281 - val_minutes_output_loss: 0.1008\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.9265 - hours_output_loss: 1.7868 - minutes_output_loss: 0.0662 - val_loss: 8.9126 - val_hours_output_loss: 17.4328 - val_minutes_output_loss: 0.3924\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.7164 - hours_output_loss: 1.3731 - minutes_output_loss: 0.0596 - val_loss: 2.5752 - val_hours_output_loss: 5.0709 - val_minutes_output_loss: 0.0795\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 5s 28ms/step - loss: 0.5761 - hours_output_loss: 1.0976 - minutes_output_loss: 0.0546 - val_loss: 1.7523 - val_hours_output_loss: 3.4502 - val_minutes_output_loss: 0.0544\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.4877 - hours_output_loss: 0.9242 - minutes_output_loss: 0.0511 - val_loss: 0.9090 - val_hours_output_loss: 1.7669 - val_minutes_output_loss: 0.0511\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.4426 - hours_output_loss: 0.8362 - minutes_output_loss: 0.0490 - val_loss: 2.7205 - val_hours_output_loss: 5.3754 - val_minutes_output_loss: 0.0656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.3974 - hours_output_loss: 0.7491 - minutes_output_loss: 0.0458 - val_loss: 3.0857 - val_hours_output_loss: 6.1076 - val_minutes_output_loss: 0.0637\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.3647 - hours_output_loss: 0.6848 - minutes_output_loss: 0.0445 - val_loss: 2.7748 - val_hours_output_loss: 5.4833 - val_minutes_output_loss: 0.0662\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.3687 - hours_output_loss: 0.6921 - minutes_output_loss: 0.0453 - val_loss: 1.8941 - val_hours_output_loss: 3.7335 - val_minutes_output_loss: 0.0547\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.3514 - hours_output_loss: 0.6592 - minutes_output_loss: 0.0435 - val_loss: 0.8489 - val_hours_output_loss: 1.6424 - val_minutes_output_loss: 0.0555\n",
      "Epoch 15/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.3223 - hours_output_loss: 0.6006 - minutes_output_loss: 0.0439 - val_loss: 3.2247 - val_hours_output_loss: 6.3894 - val_minutes_output_loss: 0.0600\n",
      "Epoch 16/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.3076 - hours_output_loss: 0.5739 - minutes_output_loss: 0.0412 - val_loss: 4.0327 - val_hours_output_loss: 7.9986 - val_minutes_output_loss: 0.0668\n",
      "Epoch 17/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2749 - hours_output_loss: 0.5081 - minutes_output_loss: 0.0417 - val_loss: 0.6638 - val_hours_output_loss: 1.2780 - val_minutes_output_loss: 0.0496\n",
      "Epoch 18/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2558 - hours_output_loss: 0.4736 - minutes_output_loss: 0.0380 - val_loss: 2.1965 - val_hours_output_loss: 4.3362 - val_minutes_output_loss: 0.0567\n",
      "Epoch 19/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2791 - hours_output_loss: 0.5191 - minutes_output_loss: 0.0390 - val_loss: 1.1566 - val_hours_output_loss: 2.2715 - val_minutes_output_loss: 0.0416\n",
      "Epoch 20/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2927 - hours_output_loss: 0.5460 - minutes_output_loss: 0.0394 - val_loss: 3.1824 - val_hours_output_loss: 6.3026 - val_minutes_output_loss: 0.0622\n",
      "Epoch 21/30\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.2765 - hours_output_loss: 0.5130 - minutes_output_loss: 0.0400 - val_loss: 4.3026 - val_hours_output_loss: 8.5342 - val_minutes_output_loss: 0.0710\n",
      "Epoch 22/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2892 - hours_output_loss: 0.5411 - minutes_output_loss: 0.0374 - val_loss: 5.3772 - val_hours_output_loss: 10.6770 - val_minutes_output_loss: 0.0774\n",
      "Epoch 23/30\n",
      "180/180 [==============================] - 5s 25ms/step - loss: 0.2949 - hours_output_loss: 0.5497 - minutes_output_loss: 0.0400 - val_loss: 5.0447 - val_hours_output_loss: 10.0130 - val_minutes_output_loss: 0.0765\n",
      "Epoch 24/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.2377 - hours_output_loss: 0.4381 - minutes_output_loss: 0.0374 - val_loss: 5.9008 - val_hours_output_loss: 11.7242 - val_minutes_output_loss: 0.0774\n",
      "Epoch 25/30\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.2908 - hours_output_loss: 0.5443 - minutes_output_loss: 0.0374 - val_loss: 4.9988 - val_hours_output_loss: 9.9139 - val_minutes_output_loss: 0.0837\n",
      "Epoch 26/30\n",
      "180/180 [==============================] - 5s 27ms/step - loss: 0.2405 - hours_output_loss: 0.4454 - minutes_output_loss: 0.0357 - val_loss: 0.9353 - val_hours_output_loss: 1.8149 - val_minutes_output_loss: 0.0557\n",
      "Epoch 27/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1968 - hours_output_loss: 0.3592 - minutes_output_loss: 0.0343 - val_loss: 0.4953 - val_hours_output_loss: 0.9576 - val_minutes_output_loss: 0.0329\n",
      "Epoch 28/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1943 - hours_output_loss: 0.3558 - minutes_output_loss: 0.0327 - val_loss: 0.4436 - val_hours_output_loss: 0.8610 - val_minutes_output_loss: 0.0263\n",
      "Epoch 29/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1890 - hours_output_loss: 0.3464 - minutes_output_loss: 0.0317 - val_loss: 1.5423 - val_hours_output_loss: 3.0275 - val_minutes_output_loss: 0.0571\n",
      "Epoch 30/30\n",
      "180/180 [==============================] - 5s 26ms/step - loss: 0.1770 - hours_output_loss: 0.3229 - minutes_output_loss: 0.0312 - val_loss: 2.9535 - val_hours_output_loss: 5.8448 - val_minutes_output_loss: 0.0622\n",
      "113/113 [==============================] - 1s 5ms/step\n",
      "Average Time Difference Error: 180.63 minutes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "images = np.load('/home/s3963616/IDL/images_L.npy')\n",
    "labels = np.load('/home/s3963616/IDL/labels.npy')\n",
    "\n",
    "\n",
    "hours = labels[:, 0]\n",
    "minutes = labels[:, 1] / 60 \n",
    "\n",
    "\n",
    "images_expanded = np.expand_dims(images, -1)\n",
    "images_expanded = images_expanded.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "X_train, X_test, y_train_hours, y_test_hours, y_train_minutes, y_test_minutes = train_test_split(\n",
    "    images_expanded, hours, minutes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(150, 150, 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(256, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)  \n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)  \n",
    "\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "hours_output = Dense(1, activation='linear', name='hours_output')(x)\n",
    "minutes_output = Dense(1, activation='linear', name='minutes_output')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[hours_output, minutes_output])\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'hours_output': 'mean_squared_error', 'minutes_output': 'mean_squared_error'},\n",
    "              loss_weights={'hours_output': 0.5, 'minutes_output': 0.5})\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.fit(X_train, {'hours_output': y_train_hours, 'minutes_output': y_train_minutes},\n",
    "          validation_split=0.2,\n",
    "          batch_size=64,\n",
    "          epochs=30)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predicted_hours, predicted_minutes = predictions[0], predictions[1]\n",
    "\n",
    "predicted_hours_converted = predicted_hours * 12  \n",
    "predicted_minutes_converted = predicted_minutes * 60  \n",
    "\n",
    "\n",
    "total_error = 0\n",
    "for i in range(len(predicted_hours_converted)):\n",
    "    pred_hour = predicted_hours_converted[i][0]\n",
    "    pred_minute = predicted_minutes_converted[i][0]\n",
    "    actual_hour = y_test_hours[i] * 12\n",
    "    actual_minute = y_test_minutes[i] * 60\n",
    "\n",
    "    error = calculate_shortest_time_difference(pred_hour, pred_minute, actual_hour, actual_minute)\n",
    "    total_error += error\n",
    "\n",
    "average_error = total_error / len(predicted_hours_converted)\n",
    "print(f\"Average Time Difference Error: {average_error:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a11b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 140)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_shortest_time_difference(predicted_hours, predicted_minutes, actual_hours, actual_minutes):\n",
    "\n",
    " \n",
    "    predicted_hours %= 12\n",
    "    actual_hours %= 12\n",
    "\n",
    "    predicted_total_minutes = predicted_hours * 60 + predicted_minutes\n",
    "    actual_total_minutes = actual_hours * 60 + actual_minutes\n",
    "\n",
    "\n",
    "    minute_difference = abs(predicted_total_minutes - actual_total_minutes)\n",
    "\n",
    "    \n",
    "    shortest_difference = min(minute_difference, 720 - minute_difference)\n",
    "\n",
    "    return shortest_difference\n",
    "\n",
    "\n",
    "example1_shortest = calculate_shortest_time_difference(0, 10, 11, 50) \n",
    "example2_shortest = calculate_shortest_time_difference(0, 10, 9, 50)  \n",
    "\n",
    "example1_shortest, example2_shortest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4969d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 150, 150, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 148, 148, 16  160         ['input_8[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 148, 148, 16  64         ['conv2d_35[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooling2D  (None, 74, 74, 16)  0           ['batch_normalization_35[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 72, 72, 32)   4640        ['max_pooling2d_35[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 72, 72, 32)  128         ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_36 (MaxPooling2D  (None, 36, 36, 32)  0           ['batch_normalization_36[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 34, 34, 64)   18496       ['max_pooling2d_36[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 34, 34, 64)  256         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_37 (MaxPooling2D  (None, 17, 17, 64)  0           ['batch_normalization_37[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 15, 15, 128)  73856       ['max_pooling2d_37[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 15, 15, 128)  512        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_38 (MaxPooling2D  (None, 7, 7, 128)   0           ['batch_normalization_38[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 5, 5, 90)     103770      ['max_pooling2d_38[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 5, 5, 90)    360         ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_39 (MaxPooling2D  (None, 2, 2, 90)    0           ['batch_normalization_39[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten_7 (Flatten)            (None, 360)          0           ['max_pooling2d_39[0][0]']       \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1024)         369664      ['flatten_7[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 1024)         0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " hours_output (Dense)           (None, 12)           12300       ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " minutes_output (Dense)         (None, 1)            1025        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 585,231\n",
      "Trainable params: 584,571\n",
      "Non-trainable params: 660\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "180/180 [==============================] - 8s 24ms/step - loss: 3.2001 - hours_output_loss: 2.4737 - minutes_output_loss: 0.7264 - hours_output_accuracy: 0.1255 - minutes_output_mse: 0.7264 - val_loss: 3.1770 - val_hours_output_loss: 2.6829 - val_minutes_output_loss: 0.4940 - val_hours_output_accuracy: 0.0906 - val_minutes_output_mse: 0.4940\n",
      "Epoch 2/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 2.1702 - hours_output_loss: 2.0571 - minutes_output_loss: 0.1131 - hours_output_accuracy: 0.2218 - minutes_output_mse: 0.1131 - val_loss: 5.7732 - val_hours_output_loss: 5.6855 - val_minutes_output_loss: 0.0878 - val_hours_output_accuracy: 0.0750 - val_minutes_output_mse: 0.0878\n",
      "Epoch 3/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 1.7751 - hours_output_loss: 1.6676 - minutes_output_loss: 0.1075 - hours_output_accuracy: 0.3412 - minutes_output_mse: 0.1075 - val_loss: 4.0045 - val_hours_output_loss: 3.9008 - val_minutes_output_loss: 0.1036 - val_hours_output_accuracy: 0.0844 - val_minutes_output_mse: 0.1036\n",
      "Epoch 4/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 1.3110 - hours_output_loss: 1.2084 - minutes_output_loss: 0.1025 - hours_output_accuracy: 0.5064 - minutes_output_mse: 0.1025 - val_loss: 1.4811 - val_hours_output_loss: 1.4082 - val_minutes_output_loss: 0.0728 - val_hours_output_accuracy: 0.4351 - val_minutes_output_mse: 0.0728\n",
      "Epoch 5/30\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.9571 - hours_output_loss: 0.8690 - minutes_output_loss: 0.0881 - hours_output_accuracy: 0.6458 - minutes_output_mse: 0.0881 - val_loss: 0.8763 - val_hours_output_loss: 0.8162 - val_minutes_output_loss: 0.0601 - val_hours_output_accuracy: 0.6885 - val_minutes_output_mse: 0.0601\n",
      "Epoch 6/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.7363 - hours_output_loss: 0.6565 - minutes_output_loss: 0.0798 - hours_output_accuracy: 0.7363 - minutes_output_mse: 0.0798 - val_loss: 2.1274 - val_hours_output_loss: 1.8827 - val_minutes_output_loss: 0.2447 - val_hours_output_accuracy: 0.3663 - val_minutes_output_mse: 0.2447\n",
      "Epoch 7/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.5788 - hours_output_loss: 0.5065 - minutes_output_loss: 0.0724 - hours_output_accuracy: 0.8048 - minutes_output_mse: 0.0724 - val_loss: 0.7564 - val_hours_output_loss: 0.6802 - val_minutes_output_loss: 0.0762 - val_hours_output_accuracy: 0.7302 - val_minutes_output_mse: 0.0762\n",
      "Epoch 8/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5025 - hours_output_loss: 0.4371 - minutes_output_loss: 0.0654 - hours_output_accuracy: 0.8301 - minutes_output_mse: 0.0654 - val_loss: 0.4667 - val_hours_output_loss: 0.4225 - val_minutes_output_loss: 0.0442 - val_hours_output_accuracy: 0.8340 - val_minutes_output_mse: 0.0442\n",
      "Epoch 9/30\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4164 - hours_output_loss: 0.3566 - minutes_output_loss: 0.0598 - hours_output_accuracy: 0.8628 - minutes_output_mse: 0.0598 - val_loss: 2.2407 - val_hours_output_loss: 2.1743 - val_minutes_output_loss: 0.0663 - val_hours_output_accuracy: 0.3288 - val_minutes_output_mse: 0.0663\n",
      "Epoch 10/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3585 - hours_output_loss: 0.3008 - minutes_output_loss: 0.0577 - hours_output_accuracy: 0.8845 - minutes_output_mse: 0.0577 - val_loss: 4.0344 - val_hours_output_loss: 3.9612 - val_minutes_output_loss: 0.0733 - val_hours_output_accuracy: 0.1934 - val_minutes_output_mse: 0.0733\n",
      "Epoch 11/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2965 - hours_output_loss: 0.2428 - minutes_output_loss: 0.0536 - hours_output_accuracy: 0.9089 - minutes_output_mse: 0.0536 - val_loss: 1.8449 - val_hours_output_loss: 1.7786 - val_minutes_output_loss: 0.0663 - val_hours_output_accuracy: 0.4323 - val_minutes_output_mse: 0.0663\n",
      "Epoch 12/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2902 - hours_output_loss: 0.2382 - minutes_output_loss: 0.0519 - hours_output_accuracy: 0.9122 - minutes_output_mse: 0.0519 - val_loss: 0.5371 - val_hours_output_loss: 0.4944 - val_minutes_output_loss: 0.0427 - val_hours_output_accuracy: 0.8059 - val_minutes_output_mse: 0.0427\n",
      "Epoch 13/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2482 - hours_output_loss: 0.1968 - minutes_output_loss: 0.0514 - hours_output_accuracy: 0.9267 - minutes_output_mse: 0.0514 - val_loss: 0.3731 - val_hours_output_loss: 0.3352 - val_minutes_output_loss: 0.0379 - val_hours_output_accuracy: 0.8747 - val_minutes_output_mse: 0.0379\n",
      "Epoch 14/30\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2264 - hours_output_loss: 0.1764 - minutes_output_loss: 0.0500 - hours_output_accuracy: 0.9352 - minutes_output_mse: 0.0500 - val_loss: 4.1606 - val_hours_output_loss: 4.0910 - val_minutes_output_loss: 0.0697 - val_hours_output_accuracy: 0.2247 - val_minutes_output_mse: 0.0697\n",
      "Epoch 15/30\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2217 - hours_output_loss: 0.1756 - minutes_output_loss: 0.0461 - hours_output_accuracy: 0.9323 - minutes_output_mse: 0.0461 - val_loss: 4.7174 - val_hours_output_loss: 4.5983 - val_minutes_output_loss: 0.1191 - val_hours_output_accuracy: 0.2531 - val_minutes_output_mse: 0.1191\n",
      "Epoch 16/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2011 - hours_output_loss: 0.1547 - minutes_output_loss: 0.0465 - hours_output_accuracy: 0.9422 - minutes_output_mse: 0.0465 - val_loss: 0.6346 - val_hours_output_loss: 0.5719 - val_minutes_output_loss: 0.0627 - val_hours_output_accuracy: 0.7875 - val_minutes_output_mse: 0.0627\n",
      "Epoch 17/30\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1863 - hours_output_loss: 0.1420 - minutes_output_loss: 0.0443 - hours_output_accuracy: 0.9485 - minutes_output_mse: 0.0443 - val_loss: 0.7237 - val_hours_output_loss: 0.6695 - val_minutes_output_loss: 0.0542 - val_hours_output_accuracy: 0.7639 - val_minutes_output_mse: 0.0542\n",
      "Epoch 18/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1771 - hours_output_loss: 0.1328 - minutes_output_loss: 0.0443 - hours_output_accuracy: 0.9546 - minutes_output_mse: 0.0443 - val_loss: 0.3404 - val_hours_output_loss: 0.2972 - val_minutes_output_loss: 0.0432 - val_hours_output_accuracy: 0.8931 - val_minutes_output_mse: 0.0432\n",
      "Epoch 19/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1839 - hours_output_loss: 0.1388 - minutes_output_loss: 0.0451 - hours_output_accuracy: 0.9510 - minutes_output_mse: 0.0451 - val_loss: 1.9753 - val_hours_output_loss: 1.9148 - val_minutes_output_loss: 0.0605 - val_hours_output_accuracy: 0.4962 - val_minutes_output_mse: 0.0605\n",
      "Epoch 20/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1449 - hours_output_loss: 0.0994 - minutes_output_loss: 0.0454 - hours_output_accuracy: 0.9633 - minutes_output_mse: 0.0454 - val_loss: 0.2461 - val_hours_output_loss: 0.2073 - val_minutes_output_loss: 0.0388 - val_hours_output_accuracy: 0.9247 - val_minutes_output_mse: 0.0388\n",
      "Epoch 21/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1516 - hours_output_loss: 0.1105 - minutes_output_loss: 0.0410 - hours_output_accuracy: 0.9608 - minutes_output_mse: 0.0410 - val_loss: 0.3113 - val_hours_output_loss: 0.2781 - val_minutes_output_loss: 0.0332 - val_hours_output_accuracy: 0.9045 - val_minutes_output_mse: 0.0332\n",
      "Epoch 22/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1622 - hours_output_loss: 0.1213 - minutes_output_loss: 0.0409 - hours_output_accuracy: 0.9568 - minutes_output_mse: 0.0409 - val_loss: 0.2368 - val_hours_output_loss: 0.1978 - val_minutes_output_loss: 0.0391 - val_hours_output_accuracy: 0.9292 - val_minutes_output_mse: 0.0391\n",
      "Epoch 23/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1747 - hours_output_loss: 0.1329 - minutes_output_loss: 0.0418 - hours_output_accuracy: 0.9519 - minutes_output_mse: 0.0418 - val_loss: 2.1139 - val_hours_output_loss: 2.0602 - val_minutes_output_loss: 0.0537 - val_hours_output_accuracy: 0.5108 - val_minutes_output_mse: 0.0537\n",
      "Epoch 24/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1467 - hours_output_loss: 0.1070 - minutes_output_loss: 0.0397 - hours_output_accuracy: 0.9612 - minutes_output_mse: 0.0397 - val_loss: 1.3821 - val_hours_output_loss: 1.3239 - val_minutes_output_loss: 0.0582 - val_hours_output_accuracy: 0.6066 - val_minutes_output_mse: 0.0582\n",
      "Epoch 25/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1500 - hours_output_loss: 0.1099 - minutes_output_loss: 0.0401 - hours_output_accuracy: 0.9609 - minutes_output_mse: 0.0401 - val_loss: 4.1963 - val_hours_output_loss: 4.1084 - val_minutes_output_loss: 0.0880 - val_hours_output_accuracy: 0.2285 - val_minutes_output_mse: 0.0880\n",
      "Epoch 26/30\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1440 - hours_output_loss: 0.1059 - minutes_output_loss: 0.0382 - hours_output_accuracy: 0.9609 - minutes_output_mse: 0.0382 - val_loss: 0.1969 - val_hours_output_loss: 0.1638 - val_minutes_output_loss: 0.0330 - val_hours_output_accuracy: 0.9503 - val_minutes_output_mse: 0.0330\n",
      "Epoch 27/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1221 - hours_output_loss: 0.0844 - minutes_output_loss: 0.0377 - hours_output_accuracy: 0.9699 - minutes_output_mse: 0.0377 - val_loss: 1.8156 - val_hours_output_loss: 1.7628 - val_minutes_output_loss: 0.0527 - val_hours_output_accuracy: 0.5684 - val_minutes_output_mse: 0.0527\n",
      "Epoch 28/30\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1137 - hours_output_loss: 0.0748 - minutes_output_loss: 0.0389 - hours_output_accuracy: 0.9741 - minutes_output_mse: 0.0389 - val_loss: 3.2241 - val_hours_output_loss: 3.1489 - val_minutes_output_loss: 0.0752 - val_hours_output_accuracy: 0.3455 - val_minutes_output_mse: 0.0752\n",
      "Epoch 29/30\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1312 - hours_output_loss: 0.0933 - minutes_output_loss: 0.0379 - hours_output_accuracy: 0.9678 - minutes_output_mse: 0.0379 - val_loss: 1.7358 - val_hours_output_loss: 1.6744 - val_minutes_output_loss: 0.0614 - val_hours_output_accuracy: 0.5431 - val_minutes_output_mse: 0.0614\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1083 - hours_output_loss: 0.0714 - minutes_output_loss: 0.0369 - hours_output_accuracy: 0.9751 - minutes_output_mse: 0.0369 - val_loss: 0.1470 - val_hours_output_loss: 0.1200 - val_minutes_output_loss: 0.0270 - val_hours_output_accuracy: 0.9597 - val_minutes_output_mse: 0.0270\n",
      "113/113 [==============================] - 1s 5ms/step\n",
      "Average Time Difference Error: 8.98 minutes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "images = np.load('/home/s3963616/IDL/images_L.npy')\n",
    "labels = np.load('/home/s3963616/IDL/labels.npy')\n",
    "\n",
    "\n",
    "hours = labels[:, 0]\n",
    "minutes = labels[:, 1] / 60 \n",
    "\n",
    "\n",
    "images_expanded = np.expand_dims(images, -1)\n",
    "images_expanded = images_expanded.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "X_train, X_test, y_train_hours, y_test_hours, y_train_minutes, y_test_minutes = train_test_split(\n",
    "    images_expanded, hours, minutes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "y_train_hours_categorical = to_categorical(y_train_hours, num_classes=12)\n",
    "y_test_hours_categorical = to_categorical(y_test_hours, num_classes=12)\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(150, 150, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "\n",
    "x = Conv2D(90, (3, 3), activation='relu')(x) \n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)  \n",
    "\n",
    "\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "hours_output = Dense(12, activation='softmax', name='hours_output')(x)  \n",
    "minutes_output = Dense(1, activation='linear', name='minutes_output')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[hours_output, minutes_output])\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'hours_output': 'categorical_crossentropy', 'minutes_output': 'mean_squared_error'},\n",
    "              metrics={'hours_output': 'accuracy', 'minutes_output': 'mse'},\n",
    "              loss_weights={'hours_output': 1.0, 'minutes_output': 1.0})\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.fit(X_train, {'hours_output': y_train_hours_categorical, 'minutes_output': y_train_minutes},\n",
    "          validation_split=0.2,\n",
    "          batch_size=64,\n",
    "          epochs=30)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predicted_hours, predicted_minutes = predictions[0], predictions[1]\n",
    "\n",
    "\n",
    "def calculate_shortest_time_difference(pred_hour, pred_minute, actual_hour, actual_minute):\n",
    "\n",
    " \n",
    "    pred_hour %= 12\n",
    "    actual_hour %= 12\n",
    "\n",
    "    \n",
    "    pred_total_minutes = pred_hour * 60 + pred_minute\n",
    "    actual_total_minutes = actual_hour * 60 + actual_minute\n",
    "\n",
    "\n",
    "    minute_difference = abs(pred_total_minutes - actual_total_minutes)\n",
    "\n",
    "   \n",
    "    shortest_difference = min(minute_difference, 720 - minute_difference)\n",
    "\n",
    "    return shortest_difference\n",
    "\n",
    "\n",
    "total_error = 0\n",
    "for i in range(len(predicted_hours)):\n",
    "    pred_hour = predicted_hours[i][0] * 12  \n",
    "    pred_minute = predicted_minutes[i][0] * 60  \n",
    "    actual_hour = y_test_hours[i] * 12\n",
    "    actual_minute = y_test_minutes[i] * 60\n",
    "\n",
    "    error = calculate_shortest_time_difference(pred_hour, pred_minute, actual_hour, actual_minute)\n",
    "    total_error += error\n",
    "\n",
    "average_error = total_error / len(predicted_hours)\n",
    "print(f\"Average Time Difference Error: {average_error:.2f} minutes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
